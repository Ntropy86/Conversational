{
  "name": "Nitigya Kargeti",
  "contact": {
    "location": "Palo Alto, CA",
    "email": "hi@ntropy.dev",
    "github": "https://github.com/Ntropy86",
    "linkedin": "https://www.linkedin.com/in/nitigyak",
    "portfolio": "https://ntropy.dev"
  },
  "headline": "Applied ML Engineer | Building Production AI Systems",
  "profile": "I build AI systems that go from research prototype to production. Currently automating data pipelines with LLMs at Dataplatr. Previously: engineered LLM-assisted educational robots deployed to 20 families (ACM CHI 2025). MS in Data Science from UW-Madison, focused on Human-AI Interaction and Brain-Computer Interfaces.\n\nMy work bridges research and engineering—taking cutting-edge ML and making it work at scale, in production, for real users.",
  "experience": [
    {
      "id": "dataplatr-consulting",
      "company": "Dataplatr Consulting",
      "role": "Data Scientist / Data Engineer",
      "dates": "Sep 2025 – Present",
      "location": "Remote (USA)",
      "icon": "/icons/exp-dataplatr.png",
      "highlights": [
        "Engineers spent 8-10h manually writing boilerplate SQL per table for Medallion pipelines → built LLM-driven code-gen tool (Databricks DLT + GPT-4) that auto-drafts L0→L3 queries with metadata enrichment → reduced effort to 3-4h review (60% time saved) across 3 Oracle/BQ schemas (1M rows, 400 MB)",
        "Wide production tables caused token-limit failures in LLM prompts → developed batch-chunking routine splitting tables into processable chunks → cut prompt runtime 40-50% in pilot tests",
        "Edge-cases like partition-clause handling weren't captured in initial tool design → partnered with BI/marketing teams to iterate on requirements, built human-in-loop UI for metadata edits → mentored 1 intern on ETL standards"
      ],
      "links": {
        "company": "https://dataplatr.com"
      },
      "technologies": ["Python", "Databricks DLT", "GPT-4", "SQL", "LLM", "ETL", "Data Engineering", "Oracle", "BigQuery"],
      "keywords": [
        "LLM-driven automation", "code generation", "SQL optimization", "batch processing",
        "token management", "human-in-loop", "data pipeline", "mentoring", "BI integration"
      ],
      "type": "experience",
      "category": "Data & AI"
    },
    {
      "id": "people-robots-lab",
      "company": "People & Robots Lab (NSF-funded), University of Wisconsin–Madison",
      "role": "Graduate Research Engineer",
      "dates": "Jan 2024 – Jan 2025",
      "location": "Madison, WI",
      "icon": "/icons/exp-uw-robots.png",
      "highlights": [
        "2nd Author, ACM CHI 2025: Wizard-of-Oz robot demo wasn't scalable for real homes → engineered full software & AI stack (GPT-4-o VLM + RAG grounding + Python/JS SDK) turning demo into deployable platform → deployed to 20-family in-home study preventing hallucinations via JSON page-context grounding",
        "Existing Misty SDK required ROS, adding complexity and 210ms API latency → refactored into lightweight Python/JS library removing ROS dependency → reduced latency 14% to 180ms; built IRB-compliant parent-approval UI ensuring all robot questions were screened before playback",
        "Study needed quantitative evidence of engagement/comprehension → performed mixed-effects statistical modeling on robot-interaction logs + survey data → results informed CHI 2025 paper findings; mentored 2 undergrads on study logistics"
      ],
      "links": {
        "lab": "https://peopleandrobots.org",
        "publication_chi": "https://dl.acm.org/doi/10.1145/3706598.3713330",
        "pdf": "https://dl.acm.org/doi/pdf/10.1145/3706598.3713330"
      },
      "technologies": ["FastAPI", "Python", "WebSockets", "MongoDB", "REST", "LLM", "RBAC", "Docker", "CI/CD"],
      "keywords": [
        "uvicorn", "pydantic", "motor (async MongoDB)", "asyncio", "OpenAPI", "JWT/OAuth2",
        "aggregation pipeline", "websocket eventing", "rate limiting", "prompt templating",
        "grounded generation", "content safety", "evals", "multi-agent orchestration",
        "policy engine", "observability", "structured logging"
      ],
      "type": "experience",
      "category": "Research & AI"
    },
    {
      "id": "spenza-inc",
      "company": "Spenza Inc. (B2B SaaS, ~8-person)",
      "role": "Software Engineer",
      "dates": "Jan 2023 – Aug 2023",
      "location": "Remote / Bengaluru, IN",
      "icon": "/icons/exp-spenza.png",
      "highlights": [
        "Platform only supported hard-coded INR currency, limiting global expansion → built dynamic multi-currency module (NestJS + MongoDB + Stripe API) with auto-FX rates and legacy-row migration → shipped 3 PRs with zero regressions, enabling currency toggle for 500+ clients",
        "Monolithic Lambda timed out on large telecom invoices (>10k pages) → designed multi-threaded AWS Lambda PDF parser for Verizon/AT&T/T-Mobile invoices (20k-page, 1M-line docs) → cut processing from timeout to ≈1 min for 400k pages",
        "Stripe account limit capped platform at 500 clients, blocking growth → led migration to Stripe Connected Accounts: coordinated with Stripe support, rewrote transaction flows, built one-click bulk-transfer tool with buffered-retry logic → removed cap, delivered 200 commits (5 PRs staging, 1 prod)"
      ],
      "technologies": ["AWS", "Lambda", "SQS", "S3", "Stripe", "Python", "Terraform"],
      "keywords": [
        "event-driven architecture", "idempotency keys", "SQS redrive policy", "exponential backoff",
        "DLQ patterns", "S3 multipart upload", "CloudWatch metrics/alarms", "X-Ray tracing",
        "IaC (Terraform)", "CI/CD pipelines", "blue-green deploy", "schema migration",
        "retry budgets", "serverless concurrency", "cold-start mitigation"
      ],
      "type": "experience",
      "category": "Software Engineering"
    },
    {
      "id": "cdac-intern",
      "company": "Centre for Development of Advanced Computing (CDAC), Govt. of India",
      "role": "R&D Engineer (Intern) — P300 BCI Keyspeller",
      "dates": "Sep 2022 – Mar 2023",
      "location": "New Delhi, IN",
      "icon": "/icons/exp-cdac.png",
      "highlights": [
        "Lab needed real-time P300 BCI system for disabled users' communication → built end-to-end key-speller pipeline with EEG acquisition (Lab Streaming Layer), preprocessing, epoching, and template-matching → achieved 97% character-selection accuracy at 50k data points/sec",
        "Legacy libmushu driver (Python-2) blocked device compatibility and had high stream-latency → ported to Python-3, then C++ using code-gen + manual debug → restored device support; rewired Python prototype into C++ circular-buffer producer/consumer design stabilizing online inference latency"
      ],
      "links": {
        "report": "/mnt/data/CDAC.pdf"
      },
      "technologies": ["EEG", "P300", "C++", "Python", "MNE", "liblsl", "ICA", "Signal Processing"],
      "keywords": [
        "event-related potentials", "ERP P300", "band-pass filtering", "artifact rejection",
        "Independent Component Analysis", "epoching", "online inference", "latency budget",
        "ring buffer", "multi-threading", "SVM", "NN classifier", "ROC/AUC"
      ],
      "type": "experience",
      "category": "Research & BCI"
    },
    {
      "id": "drdo-intern",
      "company": "Defence Research & Development Organisation (DRDO) — DEAL, Dehradun",
      "role": "Summer Vocational Trainee — Hyperspectral Remote Sensing",
      "dates": "Jun 2022 – Jul 2022",
      "location": "Dehradun, IN",
      "icon": "/icons/exp-drdo.png",
      "highlights": [
        "Implemented Linear Mixture Model (LMM) spectral unmixing and mixed-pixel classifiers (SAM/SCM) in C++ using Eigen for matrix ops.",
        "Built training/feature pipelines and produced class-proportion maps (Washington DC Mall HYDICE dataset).",
        "Optimized Spectral Angular Mapper/Spectral Correlation Mapper workflows; streamlined analysis time with vectorized routines."
      ],
      "links": {
        "report": "/mnt/data/DRDO.pdf"
      },
      "technologies": ["C++", "Eigen", "Remote Sensing", "Hyperspectral Imaging", "LMM", "SAM", "SCM"],
      "keywords": [
        "endmember extraction", "abundance estimation", "spectral libraries", "spectral angle",
        "spectral correlation", "radiometric normalization", "geoTIFF", "HYDICE DC Mall",
        "vectorization", "cache locality", "tiling", "confusion matrix", "precision/recall"
      ],
      "type": "experience",
      "category": "Research & Computer Vision"
    }
  ],
  "projects": [
    {
      "id": "chicago-crimes-forecasting",
      "title": "Chicago Crimes Forecasting & Hotspot Analysis",
      "date": "2024",
      "icon": "/icons/proj-chicago.png",
      "link": "https://github.com/Ntropy86/chicago-crimes-analysis",
      "links": {
        "demo": "https://chicago-crimes-dashboard.streamlit.app",
        "github": "https://github.com/Ntropy86/chicago-crimes-analysis"
      },
      "description": "Built GCP Medallion lakehouse processing 10-yr Chicago crime data (7.2M records); achieved 74.8% storage reduction (CSV 446.7 MB → Parquet 112.8 MB), 10× query speedup, H3 spatial clustering identified 85k crime hotspots with 99% geocoding success across resolution levels r7-r9. Architecture: BigQuery + Dataform ETL (Bronze→Silver→Gold medallion), H3 hex-binning spatial aggregation, DBSCAN clustering, Streamlit dashboard.",
      "tech_stack": {
        "backend": [
          "GCP BigQuery",
          "Medallion Architecture",
          "H3 Geospatial Clustering",
          "Python (Pandas, GeoPandas)",
          "DBSCAN Clustering"
        ],
        "frontend": [
          "Streamlit Dashboard",
          "Interactive Maps",
          "Time Series Visualization"
        ]
      },
      "technologies": ["GCP", "BigQuery", "Python", "H3", "DBSCAN", "Streamlit", "Geospatial Analysis"],
      "keywords": [
        "data lakehouse", "geospatial clustering", "crime forecasting", "hotspot analysis",
        "medallion architecture", "storage optimization", "query performance", "dashboard"
      ],
      "type": "project",
      "category": "Data Engineering",
      "metrics": "74.8% storage reduction, 10× query speedup, 85k hotspots identified"
    },
    {
      "id": "amazon-semantic-search",
      "title": "Product Semantic Search Copilot",
      "date": "2024",
      "icon": "/icons/proj-amazon.png",
      "link": "https://github.com/Ntropy86/amazon-semantic-search",
      "links": {
        "demo": "https://amazon-search-copilot.streamlit.app",
        "github": "https://github.com/Ntropy86/amazon-semantic-search"
      },
      "description": "Built hybrid semantic search indexing 120k products + 3M Amazon reviews; improved nDCG@10 by 18% (0.74→0.87), MRR@10 by 21% (0.68→0.82) on benchmarks; achieved 500 queries/min @ 2GB RAM (1-2 CPU), 300ms hybrid-only latency, 800ms with re-rank (10-20% faster on local Docker vs HF Spaces). Architecture: BM25 + BGE-small embedding index + cross-encoder re-ranker; FastAPI backend + Streamlit UI; Docker containerization with /healthz endpoint, structured JSON logs, basic rate-limiting; deployed on HF Spaces + Cloud Run.",
      "tech_stack": {
        "backend": [
          "Python (FastAPI)",
          "BM25 + BGE Embeddings",
          "Cross-Encoder Reranking",
          "FAISS Vector Search",
          "Redis Caching"
        ],
        "ml": [
          "Sentence Transformers",
          "BM25 Retrieval",
          "Cross-Encoder Reranking",
          "nDCG Evaluation"
        ]
      },
      "technologies": ["Python", "BM25", "BGE Embeddings", "FAISS", "FastAPI", "Redis", "Semantic Search"],
      "keywords": [
        "semantic search", "hybrid retrieval", "BM25", "BGE embeddings", "cross-encoder",
        "reranking", "nDCG evaluation", "vector search", "product search"
      ],
      "type": "project",
      "category": "ML & Search",
      "metrics": "18% nDCG improvement, 500 queries/min, 300ms latency, 2GB RAM"
    },
    {
      "id": "resume-ai-mode",
      "title": "Portfolio AI Mode — Resume Q&A + Hybrid Search (Voice & Text)",
      "date": "2024–2025",
      "icon": "/icons/proj-aimode.png",
      "link": "https://github.com/Ntropy86/portfolio-ai",
      "links": {
        "demo": "https://ntropy.dev"
      },
      "description": "Deployed voice + text portfolio Q&A assistant showcasing personal projects/experience; achieved 150-200ms NLP-only latency, 0.8-1.2s LLM-enhanced response time; handled ≈ 50 concurrent sessions with <1% error-rate; 92% intent-detection accuracy, 88% content-relevance on bench-tested queries; attracted ≈ 500 beta visits. Architecture: Groq LLaMA-3.1-8B / Qwen-2.5-8B FP8 via open APIs; hybrid query-processor (keyword retrieval + LLM-reasoning); FastAPI Docker backend on HF Spaces, Next.js frontend on Vercel.",
      "tech_stack": {
        "backend": [
          "FastAPI (async API server)",
          "Python (async/await patterns)",
          "OpenAI/Qwen-7B (LLM for reasoning)",
          "Whisper (speech-to-text transcription)",
          "TTS (Text-to-Speech, audio response)",
          "WebSockets (real-time streaming)",
          "JSON (resume data storage/retrieval)"
        ],
        "frontend": [
          "React/Next.js (UI framework)",
          "WebSocket Client (real-time communication)",
          "Web Audio API (voice recording & playback)",
          "Markdown Rendering (tabbed content display)"
        ]
      },
      "hybrid_search": {
        "data_foundation": {
          "resume_data.json": "295 lines structured",
          "sections": ["Experience", "Projects", "Publications", "Blog", "Education"],
          "rich_metadata": ["keywords", "technologies", "metrics"]
        },
        "query_pipeline": [
          "Step 1: Intent Detection",
          "Step 2: Keyword Extraction & Matching",
          "Step 3: Content Scoring & Selection (keyword overlap, tech stack, context, diversity)"
        ],
        "modes": [
          {
            "mode": "Query Processor Only (Fast Path)",
            "triggers": "Simple factual queries",
            "behavior": "Keyword extraction → JSON matching → return cards"
          },
          {
            "mode": "Enhanced (LLM + Hybrid)",
            "triggers": "Complex reasoning or follow-ups",
            "behavior": "LLM consumes JSON + history → rich response → dynamic cards"
          }
        ]
      },
      "example": {
        "query": "FastAPI experience",
        "matches": ["People & Robots Lab", "LLM Resume Agent project"],
        "cards": "Shows those experiences with metrics"
      },
      "technologies": ["FastAPI", "LLM", "LangChain", "WebSockets", "Whisper", "TTS", "React", "Next.js", "Web Audio API", "Markdown"],
      "keywords": [
        "hybrid search", "intent detection", "embedding retrieval", "reranking",
        "streaming responses", "voice UI", "LLM grounding", "card diversity",
        "session memory", "speech pipeline"
      ],
      "type": "project",
      "metrics": "Sub-500ms latency for streaming; context-grounded answers + dynamic cards",
      "category": "AI & Full-Stack"
    },
    {
      "id": "codeforces-potd",
      "title": "Codeforces-POTD (Chrome Extension)",
      "date": "2024",
      "icon": "/icons/proj-cf.png",
      "link": "https://chromewebstore.google.com/detail/codeforces-potd/kdpcekneldcnkajbmabmfgdpcdjdmcfd",
      "links": {
        "demo": "https://chromewebstore.google.com/detail/codeforces-potd/kdpcekneldcnkajbmabmfgdpcdjdmcfd"
      },
      "description": "Lead-designed full architecture & served as primary developer for open-source Chrome extension; achieved >2.2k active users with 4.8 rating; provides \"Problem of the Day\" feed with difficulty filter, local-storage progress-tracking, background cron-sync to Codeforces API. Architecture: layered route→controller→service backend design; cron jobs for daily global-set refresh (@1 AM), filtered-set (@2 AM), weekly streak-cleanup; extension-side hourly submission-check & 6h streak-reset.",
      "technologies": ["JavaScript", "Chrome APIs", "GitHub Actions"],
      "keywords": ["Manifest V3", "chrome.storage", "alarms API", "service worker", "rollback"],
      "type": "project",
      "metrics": "2k+ users, 4.8/5 rating",
      "category": "Web Development"
    },
    {
      "id": "external-memory-merge-sort",
      "title": "External Memory Merge Sort",
      "date": "2024",
      "icon": "/icons/proj-ems.png",
      "link": "https://github.com/gselzer/cs764-project",
      "description": "Multi-stage loser-tree external sort in C++ handling 10GB+ under constrained RAM; tuned SSD vs HDD I/O patterns.",
      "technologies": ["C++", "Algorithms", "Systems Programming"],
      "keywords": ["loser tree", "spill files", "buffer pool", "sequential I/O", "mmap"],
      "type": "project",
      "category": "Systems Programming"
    },
    {
      "id": "moody-eeg-classifier",
      "title": "Moody — Real-Time EEG Emotion Classifier (BCI)",
      "date": "2023",
      "icon": "/icons/proj-moody.png",
      "link": "https://github.com/ojas-sethi/bci-music-programming",
      "description": "EEG pipeline with sliding windows, SMOTE, Bagging+ExtraTrees; aimed at robust real-time inference.",
      "technologies": ["Python", "EEG", "scikit-learn", "SMOTE", "ExtraTrees"],
      "keywords": ["band-pass filter", "windowed features", "class imbalance", "ensemble learning"],
      "type": "project",
      "metrics": "Reported 80–100% adjusted match rates",
      "category": "AI & BCI"
    }
  ],
  "publications": [
    {
      "id": "set-paired-chi-2025",
      "title": "SET-PAiREd: Designing for Parental Involvement in Learning with an AI-Assisted Educational Robot",
      "authors": "Hui-Ru Ho, Nitigya Kargeti, Ziqi Liu, Bilge Mutlu",
      "venue": "ACM CHI 2025",
      "date": "2025-04",
      "doi": "https://doi.org/10.1145/3706598.3713330",
      "pdf": "https://dl.acm.org/doi/pdf/10.1145/3706598.3713330",
      "description": "Introduces SET scenario cards and the PAiREd interface to flexibly include parents in AI-assisted early-learning; reports an in-home study with 20 families (ages 3–5).",
      "highlights": [
        "Co-authored; owned backend & multi-agent orchestration for deployments.",
        "Parent-in-the-loop workflow for reviewing/editing LLM-generated content."
      ],
      "technologies": ["LLM", "WebSocket", "FastAPI", "MongoDB"],
      "keywords": [
        "HCI", "human-robot interaction", "parent-in-the-loop", "early childhood",
        "scenario design", "educational robotics", "field study"
      ],
      "type": "publication",
      "venue_type": "conference"
    },
    {
      "id": "osa-dcnn-2023",
      "title": "ApneaNet: A hybrid 1D-CNN–LSTM architecture for detection of Obstructive Sleep Apnea using digitized ECG signals",
      "authors": "G. Srivastava, A. Chauhan, N. Kargeti, N. Pradhan, V. S. Dhaka",
      "venue": "Biomedical Signal Processing and Control, Vol. 84 (2023), Elsevier",
      "date": "2023-07",
      "link": "https://www.sciencedirect.com/science/article/abs/pii/S1746809423001878",
      "doi": "10.1016/j.bspc.2023.104754",
      "description": "Hybrid architecture combining 1D CNN feature extraction with LSTM sequence modeling for automated OSA detection from digitized ECG signals.",
      "highlights": [
        "Contributed to ECG signal-processing pipeline and model experimentation.",
        "Explores ECG as lighter-weight alternative to PSG for OSA screening."
      ],
      "technologies": ["ECG", "1D-CNN", "LSTM", "Python", "TensorFlow/PyTorch"],
      "keywords": [
        "sleep apnea", "ECG classification", "time-series modeling", "convolutional features",
        "temporal dependencies", "biomedical signal processing"
      ],
      "type": "publication",
      "venue_type": "journal"
    }
  ],
  "blog": [
    {
      "id": "building-this-website",
      "title": "Building This Website: From Figma to Production",
      "date": "2025-01-15",
      "readingTime": "15 minutes",
      "featured": true,
      "description": "A comprehensive journey through designing, developing, and deploying this modern portfolio with AI-powered features.",
      "technologies": ["Next.js", "Tailwind", "Framer Motion", "FastAPI", "LLM"],
      "keywords": ["Design System", "Component Architecture", "AI Integration", "Performance"],
      "type": "blog"
    }
  ],
  "education": [
    {
      "id": "uw-madison-ms",
      "institution": "University of Wisconsin–Madison",
      "degree": "M.S., Data Science (Professional, non-thesis)",
      "dates": "Aug 2023 – May 2025",
      "gpa": "3.55/4.0",
      "coursework": [
        "Advanced NLP",
        "Statistical Modeling & Inference",
        "Big Data Systems",
        "Neural Networks",
        "Optimization",
        "Database Management",
        "AI"
      ],
      "type": "education",
      "category": "Masters of Science"
    },
    {
      "id": "manipal-btech",
      "institution": "Manipal University Jaipur",
      "degree": "B.Tech., Computer Science (Minor: Computational Intelligence & Deep Learning)",
      "dates": "Jul 2019 – Jul 2023",
      "gpa": "10.0/10.0",
      "achievements": ["5× Dean's List", "Student Excellence in Research Award", "10/10 GPA Award", "Vice President, CS Club"],
      "type": "education",
      "category": "Bachelors of Technology"
    }
  ],
  "certifications": [
    {
      "title": "Google Advanced Data Analytics Professional Certificate",
      "year": 2025,
      "focus": "Analytics, statistics & ML capstones"
    }
  ],
  "skills": {
    "languages": ["Python", "TypeScript/JavaScript", "SQL", "Julia"],
    "backend": ["FastAPI", "Node.js/Express", "Flask", "REST/WebSockets", "Celery", "Sentry"],
    "databases": ["PostgreSQL", "MongoDB", "Redis", "Cassandra"],
    "big_data": ["PySpark", "Kafka", "PyArrow"],
    "devops": ["AWS (Lambda, SQS, S3, EC2, EMR)", "GCP BigQuery", "Docker", "GitHub Actions", "Kubernetes"]
  }
}
